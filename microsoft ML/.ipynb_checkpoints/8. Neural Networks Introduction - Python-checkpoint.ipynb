{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "Exercise 8 - Introduction to Neural Networks\n=======\n\nOriginally hypothesised in the 1940s, neural networks are now one of the main tools used in modern AI. Neural networks can be used for both regression and categorisation applications. Recent advances with storage, processing power, and open-source tools have allowed many successful applications of neural networks in medical diagnosis, filtering explicit content, speech recognition and machine translation.\n\nIn this exercise we will compare three dog breeds, using their age, weight, and height. We will make a neural network model to classify the breeds of the dogs based on these features.\n\nNote: It's extremely common for AI practitioners to use a template such as the one below for making neural networks quickly. After you are done, feel free to play around with the template to get a feel of how you can easily adjust a neural network to your problems using Keras."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Sets up the graphing configuration\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as graph\n%matplotlib inline\ngraph.rcParams['figure.figsize'] = (15,5)\ngraph.rcParams[\"font.family\"] = 'DejaVu Sans'\ngraph.rcParams[\"font.size\"] = '12'\ngraph.rcParams['image.cmap'] = 'rainbow'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 1\n------\n\nLet's start by opening up our data and having a look at it."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport keras\nprint('keras using %s backend'%keras.backend.backend())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\n\n# Loads the dataset\ndata = pd.read_csv('Data/dog_data.csv')\n\n###--- WRITE print(data.head()) TO VIEW THE TOP 5 DATA POINTS OF THE DATA SET ---###\nprint(data.head())\n###\n\ntot = data.count\n\nprint(tot)\n\n# Defines the feature dataframe\nfeatures = data.drop(['breed'], axis = 1)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "    age  weight  height  breed\n0  9.47    6.20    6.80      1\n1  7.97    8.63    8.92      0\n2  9.51    6.40    5.78      1\n3  8.96    8.82    6.28      2\n4  8.37    3.89    5.62      1\n<bound method DataFrame.count of        age  weight  height  breed\n0     9.47    6.20    6.80      1\n1     7.97    8.63    8.92      0\n2     9.51    6.40    5.78      1\n3     8.96    8.82    6.28      2\n4     8.37    3.89    5.62      1\n5     9.46    9.56    5.77      2\n6    10.40   11.00    7.78      0\n7     9.08    7.10    5.79      1\n8     9.53    9.29    5.03      2\n9     8.57    5.09    4.05      1\n10    8.77    6.17    4.89      1\n11    8.63    3.92    4.62      1\n12    7.67    7.54    4.90      2\n13    8.25    7.94    4.75      2\n14    8.54    8.73    9.10      0\n15    9.22    8.47    8.51      0\n16    8.28    8.86    5.12      2\n17    8.52    4.98    4.74      1\n18    9.82    8.66    8.92      0\n19    9.71    5.82    4.57      1\n20    8.34    5.68    5.49      1\n21    8.51    8.01    9.13      2\n22    7.19    7.98    2.78      2\n23    8.53    9.33    5.32      2\n24    9.49    9.29    9.14      0\n25   10.50   10.60    6.68      2\n26    8.90    7.16   10.10      0\n27    9.06    4.01    5.37      1\n28    9.76    6.54    5.01      1\n29    8.42    3.38    4.16      1\n..     ...     ...     ...    ...\n170   8.38    8.69    5.06      2\n171   8.30    8.34    9.32      0\n172   8.99    4.19    5.63      1\n173   8.74    8.71    5.55      2\n174   8.50    3.55    5.81      1\n175   9.87    9.56    7.98      0\n176   6.82    6.46    2.48      2\n177   8.70    2.93    4.36      1\n178  10.10    6.75    5.12      1\n179  11.80   12.10    8.03      2\n180   9.40    5.21    6.14      1\n181   7.70    8.80    9.61      0\n182   8.92    5.24    4.35      1\n183   9.59    4.62    6.07      1\n184   9.60    5.42    7.63      1\n185   9.53    9.59    5.81      2\n186   9.32    9.32    6.27      2\n187  10.20   10.10    8.69      1\n188   9.00    9.68    6.44      2\n189  12.10   11.10    6.95      0\n190  10.40    4.64    6.01      1\n191   7.50    7.72    9.99      0\n192   9.49    4.28    6.47      1\n193   8.95    5.77    6.43      1\n194   8.90    4.67    2.88      1\n195  10.20    9.90    5.02      2\n196   7.77    3.96    4.17      1\n197   9.38    6.98    5.89      1\n198   9.00    9.06    9.59      0\n199   8.26    8.85   10.20      0\n\n[200 rows x 4 columns]>\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 2\n------\n\nOur labels are three breeds of dogs, represented numerically in our dataset, as `0`, `1`, and `2`. \n\nFor a neural network these numbers are misleading, as they might imply that breed `1` is closer to breed `2` than breed `0` is, in some way. But that is not necessarily the case here.\n\nTo allow the neural network to predict categories properly we represent categories as one-hot vectors. The labels (dog breeds) will go from being represented as `0`, `1`, and `2` to this:\n\n| breed 0 | breed 1 | breed 2 |\n|:------- |:------- |:------- |\n| `1 0 0` | `0 1 0` | `0 0 1` |\n\nSo the if the 1 is in the first position, the neural network knows that it's breed 0.\n\nIf the 1 is in the second position, the neural network knows that it's breed 1, and so on."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import OneHotEncoder\n\n# Sets the  labels (numerical)\nlabels = np.array(data['breed'])\n\n###--- REPLACE THE ??? BELOW WITH 'labels' (without the quotes) ---###\nonehot = OneHotEncoder(sparse = False).fit_transform(np.transpose([???]))\n###\n\nprint(onehot[:5])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There we go!\n\nStep 3\n-------\n\nBefore we make our model, let's get our test set and training set ready."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Take the first 4/5 of the data and assign it to training\ntrain_X = features.values[:160]\ntrain_Y = onehot[:160]\n\n# Take the last 1/5 of the data and assign it to testing\ntest_X = features.values[160:]\ntest_Y = onehot[160:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 4\n\nThat's our data ready. Now it's time to make your first neural network model!\n\nThis is the standard syntax for a model in Keras. You can always play around with adding in extra hidden layers and changing their size and activation functions later.\n\nOur **first layer** is our **input layer**, with **3 nodes** because we have three features.\n\nand then\n\nOur __second layer__ is our 1st hidden layer, so let's try **4 nodes** for it.\n\nand then\n\nOur __third layer__ is our second hidden layer, let's try **2 nodes** for it.\n\nOur **final layer** will be the **output layer**, in which we have **3 nodes**, one for each of the dog breeds."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Set a randomisation seed for replicatability.\nnp.random.seed(6)\n\n\n# This creates our base model for us to add to\n###--- REPLACE THE ??? BELOW WITH Sequential() ---###\nmodel = keras.models.???\n###\n\n###--- REPLACE THE ???s BELOW WITH THE APPROPRIATE NUMBERS OF NODES ---###\n# structure = [input nodes, hidden1 nodes, hidden2 nodes, output nodes]\nstructure = [?, ?, ?, ?]\n###\n\n# Input layer + hidden layer 1\nmodel.add(keras.layers.Dense(units=structure[1], input_dim = structure[0], activation = 'relu'))\n\n# Hidden layer 2\nmodel.add(keras.layers.Dense(units=structure[2], activation = 'relu'))\n\n# Output layer\nmodel.add(keras.layers.Dense(units=structure[3], activation = tf.nn.softmax))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Alright, that's your first model ready.\n\n('tanh' is another common activation function if you want to try it instead of relu, but it doesn't perform very well here)\n\nStep 5\n-------\n\nNext up we'll compile it and see how it runs.\n\nThere's a few parameters you can chose that change how the model trains, and end up changing how the model performs.\n\nWe will use some standard parameters for now. Feel free to experiment with some different parameters later on.\n\nIf this doesn't work, check your input the correct size for the input and output layers in step 4 (3 nodes each)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Let's compile the model\n\n###--- REPLACE THE ???'s BELOW WITH 'categorical_crossentropy', 'sgd', AND THEN 'accuracy' (INCLUDING THE QUOTES) ---###\nmodel.compile(loss = ???, optimizer = ???, metrics = [???])\n###\n\n# Time to fit the model\nprint('Starting training')\n\n###--- REPLACE THE ??? BELOW WITH train_X AND THEN train_Y ---###\ntraining_stats = model.fit(???, ???, batch_size = 1, epochs = 24, verbose = 0)\n###\n\nprint('Training finished')\nprint('Training Evaluation: loss = %0.3f, accuracy = %0.2f%%'\n      %(training_stats.history['loss'][-1], 100 * training_stats.history['acc'][-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "See? Neural networks aren't hard at all.\n\n`'adam'` is another popular optimizer if you want to try it instead of `'sgd'`\n\nLets plot it!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "accuracy, = graph.plot(training_stats.history['acc'],label = 'Accuracy')\ntraining_loss, = graph.plot(training_stats.history['loss'],label = 'Training Loss')\n\n\ngraph.legend(handles = [accuracy,training_loss])\nloss = np.array(training_stats.history['loss'])\nxp = np.linspace(0, loss.shape[0], 10 * loss.shape[0])\ngraph.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\ngraph.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\ngraph.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 6\n------\n\nNow that our model is trained and ready, let's see how it performs on our test data!\n\nIt's important to test a model on data that it has never seen before, to make sure it doesn't overfit. Now let's evaluate it against the test set:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ???'s BELOW WITH test_X AND test_Y ---###\nevaluation = model.evaluate(???, ???, verbose=0)\n###\n\nprint('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f' %(evaluation[0], 100*evaluation[1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It seems to be very accurate with the random seed that we set, but let's see how it predicts something completely new and unclassified!\n\nCome up with a brand new sample of the format `[age, weight, height]` to test it with."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ?'S BELOW WITH A WHATEVER NUMBERS YOU WANT, e.g. [9, 7, 7] ---###\n# [age, weight, height]\nnew_sample = [?, ?, ?]\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Let's have a look at where our new sample sits in the feature space.\n\n# Plots out the age-weight relationship\n\n###--- REPLACE THE ???s BELOW WITH new_sample ---###\ngraph.plot(???[0], ???[1], 'ko', marker='x')\n###\n\ngraph.scatter(train_X[:,0], train_X[:,1], c = labels[:160])\ngraph.title('samples by age and weight')\ngraph.xlabel('age')\ngraph.ylabel('weight')\ngraph.show()\n\n# Plot out the age-height relationship\n\n###--- REPLACE THE ???s BELOW WITH new_sample ---###\ngraph.plot(???[0], ???[2], 'ko', marker='x')\n###\n\ngraph.scatter(train_X[:,0], train_X[:,2], c = labels[:160])\ngraph.title('samples by age and height')\ngraph.xlabel('age')\ngraph.ylabel('height')\ngraph.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Looks alright? Now let's see what breed of dog the model says it is!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ???s BELOW WITH new_sample ---###\npredicted = model.predict(np.array([???]))\nprint('Breed prediction for %s:' %(???))\n###\n\nprint(np.around(predicted[0],2))\nprint('Breed %s, with %i%% certainty.' %(np.argmax(predicted), np.round(100 * predicted[:, np.argmax(predicted)][0])))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Breed `0` should be blue, breed `1` should be green, and breed `2` should be red. How does the model's prediction compare to how you would pick this new sample's class?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Conclusion\n------\n\nWe've built a simple neural network to help us predict dog breeds! In the next exercise we'll look into neural networks with a bit more depth, and at the factors that influence how well it learns.\n\nIf you want to play around with this neural network and a new data set, just remember to set your input and output sizes correctly."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}