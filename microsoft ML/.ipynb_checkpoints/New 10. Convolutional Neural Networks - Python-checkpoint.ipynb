{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Convolutional Neural Networks\n=========\n\nConvolutional neural networks (CNNs) are a class of deep neural networks, usually used in computer vision applications.\n\nConvolutional refers the network pre-processing data for you, which traditionally was programmed by data scientists. But this type of neural network can learn how to do a lot of the pre-processing by *itself* - applying filters for things such as edge detection.\n\nHere we will do a common CNN programming exercise - recognising handwritten digits using the MNIST digit dataset."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 1\n------\n\nLet's start by loading our libraries, dataset and setting up our test, train, and validation sets."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run this!\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf\nimport numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n# Sets up the graphing configuration\nimport matplotlib.pyplot as graph\n%matplotlib inline\ngraph.rcParams['figure.figsize'] = (15,5)\ngraph.rcParams[\"font.family\"] = 'DejaVu Sans'\ngraph.rcParams[\"font.size\"] = '12'\ngraph.rcParams['image.cmap'] = 'rainbow'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.datasets import mnist\n\n# This is our training data, with 6400 samples.\n###--- REPLACE THE ???s BELOW WITH initial_train_X AND THEN initial_train_Y ---###\n??? = mnist.load_data()[0][0][:6400].astype('float32')\n??? = mnist.load_data()[0][1][:6400]\n###\n\n# This is our test data, with 2000 samples.\n###--- REPLACE THE ???s BELOW WITH initial_test_X AND THEN initial_test_Y ---###\n??? = mnist.load_data()[1][0][-2000:].astype('float32')\n??? = mnist.load_data()[1][1][-2000:]\n###\n\n# This is our validation data, with 1600 samples.\n###--- REPLACE THE ???s BELOW WITH initial_valid_X AND THEN initial_valid_Y ---###\n??? = mnist.load_data()[1][0][:1600].astype('float32')\n??? = mnist.load_data()[1][1][:1600]\n###\n\nprint('initial_train_X:', initial_train_X.shape, end = ' ')\nprint('initial_train_Y:', initial_train_Y.shape)\nprint('initial_test_X:', initial_test_X.shape, end = ' ')\nprint('initial_test_Y:', initial_test_Y.shape)\nprint('initial_valid_X:', initial_valid_X.shape, end = ' ')\nprint('initial_valid_Y:', initial_valid_Y.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Expected output:  \n```initial_train_X: (6400, 28, 28) initial_train_Y: (6400,)\ninitial_test_X: (2000, 28, 28) initial_test_Y: (2000,)\ninitial_valid_X: (1600, 28, 28) initial_valid_Y: (1600,)```  "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "__So we have:__\n* 6400 training samples\n* 1600 validation samples\n* 2000 test samples\n\nStep 2\n------\n\nLet's take a look at one of the images."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ??? BELOW WITH initial_train_X[0] (or another number you want to see) ---###\ngraph.imshow(???, cmap = 'gray', interpolation = 'nearest')\n###\n\ngraph.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You should see a black and white digit.\n  \n__Each image:__\n* Is black and white\n* Is 28 pixels by 28 pixels\n* This is represented by a 28 x 28 table of numbers (matrix, or DataFrame)\n\n__Each number in the 28 x 28 table that represents the image:__\n* Represents one pixel\n* Is on a scale of 0 to 255\n* 0 is fully black\n* 255 is fully white\n* In between 0 and 255 is shades of grey."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 3\n-------\n\nWe'll need to play around with our data to get it working well with our neural network. \n\nFirst off, let's reshape our `initial_train_X, initial_test_X and initial_valid_X` sets so that they fit the convolutional layers.\n\nWe'll save them to a new variable, so if you run the cell twice you won't get errors."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We'll make a variable dim, to represent our image dimensions\n# Then we'll reshape the data sets using reshape\n\n# Image dimensions\ndim = initial_train_X[0].shape[0] # 28\n\n# Here reshape will change the data sets shapes using our dim variable\n\n###--- REPLACE THE ???s BELOW WITH reshape ---###\ntrain_X = initial_train_X.???(train_X.shape[0], dim, dim, 1)\ntest_X = initial_test_X.???(test_X.shape[0], dim, dim, 1)\nvalid_X = initial_valid_X.???(valid_X.shape[0], dim, dim, 1)\n###\n\n# It's more efficient if we scale our values so they're between 0 and 1\n# Not 0 and 255\n\n# Here we use feature scaling\ntrain_X = train_X / 255\nvalid_X = valid_X / 255\ntest_X = test_X / 255\n\nprint(\"Shapes of train, test and validation sets: \")\nprint(\"Train: \", train_X.shape)\nprint(\"Test: \", test_X.shape)\nprint(\"Validation: \", valid_X.shape)\nprint(\"Range: \", np.min(train_X), \"to\", np.max(train_X))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Expected output:  \n```Train:  (6400, 28, 28, 1)\nTest:  (2000, 28, 28, 1)\nValidation:  (1600, 28, 28, 1)\nRange:  0.0 to 1.0```"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Let's take a look at our expected output\n###--- WRITE print(initial_train_Y[0]) BELOW ---###\n\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Expected output: `5`\n\nOur expected output (the label) is represented by a number - the number that is shown in the training image.\n\nStep 4\n------\n\nAs with the dog dataset in exercises 8 and 9, the neural network needs this number represented in a one-hot vector.\n\nIf we were to give this to the neural network as-is, we would be implying that there is some relationship between the classes(i.e. 5 is more closely related to 4 then 5 is to 3)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This converts the output  to categorical one-hot vectors\n\n###--- REPLACE THE ???s BELOW WITH to_categorical ---###\ntrain_Y = keras.utils.???(train_Y, 10)\nvalid_Y = keras.utils.???(valid_Y, 10)\ntest_Y = keras.utils.???(test_Y, 10)\n###\n\n# 10 being the number of classes (digits 0 to 9)\n\nprint(train_Y[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Step 5\n\nTrain a network!\n\nHere we'll do the convolutional layers"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Sets a randomisation seed for replicatability.\nnp.random.seed(6)\n\n###--- REPLACE THE ??? BELOW WITH Sequential ---###\nmodel = ???()\n###",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The `convolutional` in Convolutional Neural Networks means the pre-processing the network does for you.\n\nKeras makes this easy."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Our input is a 2D image, so we'll use Conv2D\n\n###--- REPLACE THE ???s BELOW WITH Conv2D ---###\nmodel.add(???(28, kernel_size = (3, 3), activation = 'relu', input_shape = (dim, dim, 1)))\nmodel.add(???(56, (3, 3), activation = 'relu'))\n###\n\n# Next up we'll use MaxPooling\n# This helps simplify the data\n\n###--- REPLACE THE ??? BELOW WITH MaxPooling2D ---###\nmodel.add(???(pool_size = (2, 2)))\n###\n\n# Next we'll use Dropout\n# Dropout is a method that helps prevent overfitting\n# It 'drops out' (disables) nodes in the network\n\n###--- REPLACE THE ??? BELOW WITH Dropout ---###\nmodel.add(???(0.125))\n###\n\n# The higher the dropout, the more nodes are turned off.\n# Dropout increase training time\n\n# Next we flatten the data set so the rest of the network can use it\n\n###--- REPLACE THE ??? BELOW WITH Flatten ---###\nmodel.add(???())\n###\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here we applied the convolutional layers to do the pre-processing for us, and flattened the data so we can analyse it and output labels.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Regular dense layer, with some additional dropout\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.25))\n\n# Now we add our output layer to return out target probability vector.\n\n###--- REPLACE ??? BELOW WITH 10 - THE NUMBER OF CLASSES (DIGITS 0 TO 9) ---###\nmodel.add(Dense(???, activation = tf.nn.softmax))\n###\n\n# And finally, we compile.\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'Adamax', metrics = ['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 6\n------\n\nLet's train it! (this might take a little while)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ???s BELOW WITH train_X, train_Y, valid_X, AND THEN valid_Y ---###\ntraining_stats = model.fit(???, ???, batch_size = 128, epochs = 12, verbose = 1, validation_data = (???, ???))\n###\n\n###--- REPLACE THE ??? BELOW WITH evaluate ---###\nevaluation = model.???(test_X, test_Y, verbose=0)\n###\n\nprint('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f' %(evaluation[0], 100 * evaluation[1]))\n\n# We can plot our training statistics to see how it developed over time\naccuracy, = graph.plot(training_stats.history['acc'], label = 'Accuracy')\ntraining_loss, = graph.plot(training_stats.history['loss'], label = 'Training Loss')\ngraph.legend(handles = [accuracy, training_loss])\nloss = np.array(training_stats.history['loss'])\nxp = np.linspace(0,loss.shape[0],10 * loss.shape[0])\ngraph.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\ngraph.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\ngraph.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Step 6\n-------\n\nLet's test it on a new sample that it hasn't seen, and see how it classifies it!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "###--- REPLACE THE ??? BELOW WITH test_X[0] (or any other number between 0 and 1999) ---###\nsample = ???.reshape(dim, dim)\n###\n\ngraph.imshow(sample, cmap = 'gray', interpolation = 'nearest')\ngraph.show()\n\nprediction = model.predict(sample.reshape(1, dim, dim, 1))\nprint('prediction: %i (%s)' %(np.argmax(prediction), prediction))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "How is the prediction? Does it look right?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Conclusion\n-------\n\nWe've built a convolutional neural network that is able to recognise handwritten digits with very high accuracy. Well done!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}